# ======================================
# 模型指定 (明确指定默认模型)
# ======================================
model: RaSeRec  # 设置默认模型为RaSeRec

## model config
#embedding_size: 32
# dataset config

# ======================================
# 数据集配置
# ======================================
# MovieLens, Amazon
field_separator: "\t" #指定数据集field的分隔符
seq_separator: " " #指定数据集中token_seq或者float_seq域里的分隔符
USER_ID_FIELD: user_id #指定用户id域
ITEM_ID_FIELD: item_id #指定物品id域
RATING_FIELD: rating #指定打分rating域
TIME_FIELD: timestamp #指定时间域

#指定从什么文件里读什么列，这里就是从ml-1m.inter里面读取user_id, item_id, rating, timestamp这四列,剩下的以此类推
load_col:
    inter: [user_id, item_id, rating, timestamp]

NEG_PREFIX: neg_ #指定负采样前缀
LABEL_FIELD: label #指定标签域
ITEM_LIST_LENGTH_FIELD: item_length #指定序列长度域
LIST_SUFFIX: _list #指定序列前缀
MAX_ITEM_LIST_LENGTH: 50 #指定最大序列长度
POSITION_FIELD: position_id #指定生成的序列位置id

#max_user_inter_num: 100
min_user_inter_num: 5
#max_item_inter_num: 100
min_item_inter_num: 5
#lowest_val:
#    timestamp: 1546264800
#highest_val:
#    timestamp: 1577714400

# ======================================
# 训练设置
# ======================================
epochs: 10 #训练的最大轮数
train_batch_size: 1024 #训练的batch_size
learner: adam #使用的pytorch内置优化器
learning_rate: 0.001 #学习率
training_neg_sample_num: 0 #负采样数目
eval_step: 1 #每次训练后做evalaution的次数
stopping_step: 5 #控制训练收敛的步骤数，在该步骤数内若选取的评测标准没有什么变化，就可以提前停止了
weight_decay: 0

# ======================================
# 评估设置
# ======================================
eval_batch_size: 256 #评测的batch_size
eval_setting: TO_LS,full #对数据按时间排序，设置留一法划分数据集，并使用全排序
metrics: ["Recall", "NDCG"] #评测标准
valid_metric: Recall@10 #选取哪个评测标准作为作为提前停止训练的标准
topk: [5, 10, 20, 50]

# ======================================
# 目录设置
# ======================================
log_root: "./log/"
data_path: ".dataset"

# ======================================
# Transformer模型参数 
# ======================================
n_layers: 2              # Transformer层数
n_heads: 2               # 注意力头数
hidden_size: 64          # 隐藏层维度
inner_size: 256          # 内部前馈网络大小
hidden_dropout_prob: 0.5 # 隐藏层dropout
attn_dropout_prob: 0.5   # 注意力dropout
hidden_act: 'gelu'       # 激活函数
layer_norm_eps: 1e-12    # 层归一化参数
initializer_range: 0.02  # 初始化范围
loss_type: 'CE'          # 使用交叉熵损失

# ======================================
# RaSeRec特定参数
# ======================================
nprobe: 1
alpha: 0.8               # 原始知识混合比例
top_k: 10                # 检索的序列数量
low_popular: 100         # 序列长度阈值，用于决定是否使用检索增强
len_lower_bound: -1      # 序列长度下界，默认不限制
len_upper_bound: -1      # 序列长度上界，默认不限制
len_bound_reverse: True

# ======================================
# RetrieverEncoder参数
# ======================================
retriever_layers: 1         # RetrieverEncoder层数
retriever_temperature: 0.1  # 检索温度参数
recommendation_temperature: 0.1  # 推荐温度参数
retriever_dropout: 0.5     # RetrieverEncoder dropout率
kl_weight: 1                # KL散度损失权重

# ======================================
# 预训练设置（可选）
# ======================================
# 预训练模型路径 (通过命令行参数传递或留空)

pretrained_path: "./log/DuoRec/Amazon_Beauty/bs1024-lmd0.1-sem0.1-us_x-Mar-19-2025_21-16-57-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth"